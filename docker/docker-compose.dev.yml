# EDDA TTS Service - Dev Machine (RTX 5070 Ti - Blackwell)
#
# Runs only the Chatterbox TTS service for use as primary TTS endpoint.
# Uses Blackwell-specific Dockerfile with CUDA 12.8+ and PyTorch 2.7+.
# The basement server will failover to this when available.
#
# Usage:
#   docker compose -f docker-compose.dev.yml up -d    # Start
#   docker compose -f docker-compose.dev.yml down     # Stop
#   docker compose -f docker-compose.dev.yml logs -f  # View logs
#
# Auto-start on boot:
#   sudo systemctl enable edda-tts-dev
#
# Network: Listens on 0.0.0.0:5000 so basement server can reach it

services:
  tts:
    build:
      context: ../tts-service
      dockerfile: Dockerfile.blackwell
    container_name: edda-tts-dev
    runtime: nvidia
    ports:
      - "5000:5000"  # Exposed to LAN for basement server
    environment:
      - TTS_DEVICE=cuda
      - TTS_PORT=5000
      - LOG_LEVEL=INFO
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - HF_TOKEN=${HF_TOKEN}  # Required for Chatterbox Turbo
    volumes:
      - ../voices:/app/voices:ro
      - tts-voice-cache:/tmp/edda-voice-cache  # Persist uploaded voice references
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

volumes:
  tts-voice-cache:
    driver: local

networks:
  default:
    name: edda-tts-network
