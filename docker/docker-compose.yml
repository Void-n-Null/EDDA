# EDDA Docker Compose Configuration
#
# Services:
#   - tts: Chatterbox Turbo TTS (GPU-accelerated, high quality, slower)
#   - piper: Piper TTS (CPU, lower quality, much faster)
#   - qdrant: Vector database for conversation memory
#
# Usage:
#   docker-compose up -d              # Start all services
#   docker-compose logs -f tts        # View Chatterbox logs
#   docker-compose logs -f piper      # View Piper logs
#   docker-compose down               # Stop all services
#
# TTS Selection:
#   - Chatterbox (port 5000): High quality, ~2-3x realtime on GPU, NVIDIA runtime required
#   - Piper (port 5001): Good quality, 20-50x realtime, CPU only
#   Set TTS_BASE_URL environment variable in C# server to switch.
#
# IMPORTANT: Chatterbox requires the NVIDIA Container Toolkit and runtime: nvidia
#
# Note: The C# server runs directly on the host, not in Docker.

# Docker Compose v2 (no version field needed)
services:
  # ============================================================================
  # Chatterbox Turbo TTS Service
  # ============================================================================
  tts:
    build:
      context: ../tts-service
      dockerfile: Dockerfile
    container_name: edda-tts
    runtime: nvidia  # Use NVIDIA runtime for GPU access
    ports:
      - "5000:5000"
    environment:
      - TTS_DEVICE=cuda
      - TTS_PORT=5000
      - LOG_LEVEL=INFO
      - NVIDIA_VISIBLE_DEVICES=all  # Make GPU visible to container
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility  # Required for CUDA
      - HF_TOKEN=${HF_TOKEN}  # Required for Chatterbox Turbo
    volumes:
      # Mount voice reference files (for voice cloning)
      # :z enables SELinux shared label for container access
      - ../voices:/app/voices:ro,z
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s  # Model loading takes time
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ============================================================================
  # Piper TTS Service (Fast Alternative)
  # ============================================================================
  piper:
    build:
      context: ../piper-service
      dockerfile: Dockerfile
    container_name: edda-piper
    ports:
      - "5001:5001"
    environment:
      - TTS_PORT=5001
      - LOG_LEVEL=INFO
      - PIPER_MODEL=en_US-lessac-medium
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s  # Piper loads fast
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

  # ============================================================================
  # Qdrant Vector Database
  # ============================================================================
  qdrant:
    image: qdrant/qdrant:v1.12.1
    container_name: edda-qdrant
    ports:
      - "6333:6333"   # REST API
      - "6334:6334"   # gRPC
    volumes:
      - qdrant-data:/qdrant/storage
    environment:
      - QDRANT__LOG_LEVEL=INFO
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/readiness"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

volumes:
  qdrant-data:
    driver: local

networks:
  default:
    name: edda-network

